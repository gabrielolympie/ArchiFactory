{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313550f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "## Auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "        \n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float32\n",
    "print(f\"Using dtype: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6c243",
   "metadata": {},
   "source": [
    "## Helper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632de338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_utils import create_model, create_dataset, train_loop\n",
    "\n",
    "device=\"cuda\"\n",
    "dtype=torch.bfloat16\n",
    "\n",
    "# model and dataset\n",
    "model_id = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "dataset_id = 'roneneldan/TinyStories'\n",
    "\n",
    "# train hp\n",
    "epochs=1\n",
    "\n",
    "bs_factor = 2\n",
    "\n",
    "batch_size = 32 * bs_factor\n",
    "max_length = 128\n",
    "\n",
    "train_steps = 32768 // bs_factor\n",
    "# train_steps = 256\n",
    "val_steps = 256\n",
    "\n",
    "## train for train_steps steps\n",
    "num_train_samples = batch_size * train_steps\n",
    "num_test_samples = batch_size * val_steps\n",
    "\n",
    "# Load model\n",
    "tokenizer, embed_tokens, lm_head, norm, vocab_size, hidden_size = create_model(model_id)\n",
    "\n",
    "# load dataset\n",
    "raw_train_set, raw_test_set = create_dataset(\n",
    "    dataset_id,\n",
    "    split=\"train\",\n",
    "    field = \"text\",\n",
    "    num_train_samples = num_train_samples,\n",
    "    num_test_samples = num_test_samples,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83007f5-cb00-4333-a690-be4798746dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_train_set = [elt[:max_length * 5] for elt in tqdm(raw_train_set)]\n",
    "# raw_test_set = [elt[:max_length * 5] for elt in tqdm(raw_test_set)]\n",
    "\n",
    "# def batch_tokenize(tokenizer, texts, batch_size=256, max_length=512, device='cuda'):\n",
    "#     tokenized_batch = []\n",
    "#     for i in tqdm(range(0, len(texts), batch_size)):\n",
    "#         batch = texts[i:i + batch_size]\n",
    "#         tokenized = tokenizer(batch, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')['input_ids']\n",
    "#         tokenized_batch.append(tokenized)\n",
    "#     return torch.cat(tokenized_batch, dim=0)\n",
    "\n",
    "# train_set = batch_tokenize(tokenizer, raw_train_set, batch_size=256, max_length=max_length)\n",
    "# test_set = batch_tokenize(tokenizer, raw_test_set, batch_size=64, max_length=max_length)\n",
    "\n",
    "import pickle\n",
    "# with open('/home/golympie/tokenized_dataset.pickle', 'wb') as f:\n",
    "#     pickle.dump((train_set, test_set), f)\n",
    "\n",
    "with open('/home/golympie/tokenized_dataset.pickle', 'rb') as f:\n",
    "    train_set, test_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8cba9cb-6b89-434d-8890-49336aad055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbaba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Partial train function\n",
    "def train(module, run_name, do_compile=False):\n",
    "    return train_loop(\n",
    "        module,\n",
    "        run_name,\n",
    "        do_compile,\n",
    "        tokenizer,\n",
    "        device,\n",
    "        dtype,\n",
    "        train_set,\n",
    "        test_set,\n",
    "        epochs,\n",
    "        batch_size,\n",
    "        max_length,\n",
    "        embed_tokens,\n",
    "        lm_head,\n",
    "        norm,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53a2d8",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92fb0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.archi_modules import StackedMixinBlock, count_parameters\n",
    "from modules.positionnal_modules import NaivePositionnalEmbedding\n",
    "\n",
    "from modules.mixin_modules import (\n",
    "    RNNMixin,\n",
    "    LSTMMixin,\n",
    "    MultiScaleRetentionMixin,\n",
    "    Mamba2Mixin,\n",
    "    RWKV6Mixin,\n",
    "    GroupedQuerySelfAttentionMixin,\n",
    "    MultiHeadLatentAttentionMixin,\n",
    ")\n",
    "\n",
    "from modules.ffn_modules import FFN, SparseMoeFFN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc39648",
   "metadata": {},
   "source": [
    "## STACK 4 - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2b82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "ffn_module = FFN(hidden_size, hidden_size*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abd6ee",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881977bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lstm = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=LSTMMixin(hidden_size),\n",
    "    ffn_module=ffn_module,\n",
    ")\n",
    "\n",
    "count_parameters(lstm)\n",
    "train(lstm, run_name='lstm', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4127485",
   "metadata": {},
   "source": [
    "### GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gqsa = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=GroupedQuerySelfAttentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(gqsa)\n",
    "train(gqsa,run_name='gqsa', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815970d",
   "metadata": {},
   "source": [
    "### MHLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70801fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 30,053,664\n",
      "Mixin parameters: 6,088,608\n",
      "FFN parameters: 23,891,328\n",
      "Using 16 workers for DataLoader.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4b19d07c204146b46e4ee2f5e78c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa075e2afaa44b0eb1b02a03155e4b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 s, sys: 3.36 s, total: 43.9 s\n",
      "Wall time: 45 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mmhla = StackedMixinBlock(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    num_layers=num_layers,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    hidden_size=hidden_size,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    initializer_range=0.02,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    mixin_module=MultiHeadLatentAttentionMixin(hidden_size, num_attention_heads=9),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ffn_module=ffn_module,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mcount_parameters(mhla)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtrain(mhla,run_name=\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmhla\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, do_compile=False)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/IPython/core/magics/execution.py:1470\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/IPython/core/magics/execution.py:1439\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m expr_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1438\u001b[39m         code_2 = \u001b[38;5;28mself\u001b[39m.shell.compile(expr_val, source, \u001b[33m'\u001b[39m\u001b[33meval\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m         out = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1441\u001b[39m     captured_exception = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:11\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(module, run_name, do_compile)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(module, run_name, do_compile=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/gabol/Desktop/ArchiFactory/utils/train_utils.py:150\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(module, run_name, do_compile, tokenizer, device, dtype, train_set, test_set, epochs, batch_size, max_length, embed_tokens, lm_head, norm)\u001b[39m\n\u001b[32m    147\u001b[39m loss = loss_fn(shift_logits, shift_labels)\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m optimizer.step()\n\u001b[32m    152\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mhla = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=MultiHeadLatentAttentionMixin(hidden_size, num_attention_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mhla)\n",
    "train(mhla,run_name='mhla', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d42d8",
   "metadata": {},
   "source": [
    "### Retentive Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "retnet = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=MultiScaleRetentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(retnet)\n",
    "train(retnet,run_name='retnet', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6f066",
   "metadata": {},
   "source": [
    "### Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mamba = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=Mamba2Mixin(hidden_size = hidden_size, num_attention_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mamba)\n",
    "train(mamba,run_name='mamba', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d11bb",
   "metadata": {},
   "source": [
    "### RWKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad291e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rwkv = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=RWKV6Mixin(hidden_size = hidden_size, num_attention_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(rwkv)\n",
    "train(rwkv,run_name='rwkv', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b981c5",
   "metadata": {},
   "source": [
    "## STACK 8 - Moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9471ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "ffn_module = SparseMoeFFN(\n",
    "    hidden_size,\n",
    "    hidden_size*4,\n",
    "    num_experts=4,\n",
    "    num_experts_per_tok=1,\n",
    "    norm_topk_prob=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae8d8f",
   "metadata": {},
   "source": [
    "### LSTM MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lstm_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=LSTMMixin(hidden_size),\n",
    "    ffn_module=ffn_module,\n",
    ")\n",
    "\n",
    "count_parameters(lstm_moe)\n",
    "train(lstm_moe, run_name='lstm-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b43ba",
   "metadata": {},
   "source": [
    "### GQA MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gqsa_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=GroupedQuerySelfAttentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(gqsa_moe)\n",
    "train(gqsa_moe,run_name='gqsa-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f846c5d",
   "metadata": {},
   "source": [
    "### MHLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mhla_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=MultiHeadLatentAttentionMixin(hidden_size, num_attention_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mhla_moe)\n",
    "train(mhla_moe,run_name='mhla-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd0af3",
   "metadata": {},
   "source": [
    "### Retentive Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "retnet_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=MultiScaleRetentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(retnet_moe)\n",
    "train(retnet_moe,run_name='retnet-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0cc33b",
   "metadata": {},
   "source": [
    "### Mamba MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mamba_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=Mamba2Mixin(hidden_size = hidden_size, num_attention_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mamba_moe)\n",
    "train(mamba_moe,run_name='mamba-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ab488",
   "metadata": {},
   "source": [
    "### RWKV MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rwkv_moe = StackedMixinBlock(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    mixin_module=RWKV6Mixin(hidden_size = hidden_size, num_attention_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(rwkv_moe)\n",
    "train(rwkv_moe,run_name='rwkv-moe', do_compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3caec-54d3-46d1-94cb-e5096b687f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
