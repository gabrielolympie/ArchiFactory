{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313550f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "## Auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "        \n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float32\n",
    "print(f\"Using dtype: {dtype}\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREAD']='16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6c243",
   "metadata": {},
   "source": [
    "## Helper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632de338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_utils import create_model, create_dataset, train_loop\n",
    "\n",
    "device=\"cuda\"\n",
    "dtype=torch.bfloat16\n",
    "\n",
    "# model and dataset\n",
    "model_id = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n",
    "dataset_id = 'roneneldan/TinyStories'\n",
    "\n",
    "# train hp\n",
    "epochs=1\n",
    "\n",
    "num_samples = 1000000\n",
    "\n",
    "bs_factor = 1\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 128\n",
    "\n",
    "train_steps = num_samples // batch_size\n",
    "# train_steps = 256\n",
    "val_steps = 256\n",
    "\n",
    "## train for train_steps steps\n",
    "num_train_samples = batch_size * train_steps\n",
    "num_test_samples = batch_size * val_steps\n",
    "\n",
    "# Load model\n",
    "tokenizer, embed_tokens, lm_head, norm, vocab_size, hidden_size = create_model(model_id)\n",
    "\n",
    "# load dataset\n",
    "raw_train_set, raw_test_set = create_dataset(\n",
    "    dataset_id,\n",
    "    split=\"train\",\n",
    "    field = \"text\",\n",
    "    num_train_samples = num_train_samples,\n",
    "    num_test_samples = num_test_samples,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83007f5-cb00-4333-a690-be4798746dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_train_set = [elt[:max_length * 5] for elt in tqdm(raw_train_set)]\n",
    "# raw_test_set = [elt[:max_length * 5] for elt in tqdm(raw_test_set)]\n",
    "\n",
    "# def batch_tokenize(tokenizer, texts, batch_size=256, max_length=512, device='cuda'):\n",
    "#     tokenized_batch = []\n",
    "#     for i in tqdm(range(0, len(texts), batch_size)):\n",
    "#         batch = texts[i:i + batch_size]\n",
    "#         tokenized = tokenizer(batch, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')['input_ids']\n",
    "#         tokenized_batch.append(tokenized)\n",
    "#     return torch.cat(tokenized_batch, dim=0)\n",
    "\n",
    "# train_set = batch_tokenize(tokenizer, raw_train_set, batch_size=256, max_length=max_length)\n",
    "# test_set = batch_tokenize(tokenizer, raw_test_set, batch_size=64, max_length=max_length)\n",
    "\n",
    "\n",
    "# with open('/home/golympie/tokenized_dataset.pickle', 'wb') as f:\n",
    "#     pickle.dump((train_set, test_set), f)\n",
    "\n",
    "with open('/home/golympie/tokenized_dataset.pickle', 'rb') as f:\n",
    "    train_set, test_set = pickle.load(f)\n",
    "\n",
    "\n",
    "train_set = train_set.to('cuda')\n",
    "test_set = test_set.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbaba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Partial train function\n",
    "def train(module, run_name, do_compile=False):\n",
    "    return train_loop(\n",
    "        module,\n",
    "        run_name,\n",
    "        do_compile,\n",
    "        tokenizer,\n",
    "        device,\n",
    "        dtype,\n",
    "        train_set,\n",
    "        test_set,\n",
    "        epochs,\n",
    "        batch_size,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc53a2d8",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fb0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.archi_modules import StackedMixinForCausalLM, count_parameters\n",
    "from modules.positionnal_modules import NaivePositionnalEmbedding\n",
    "\n",
    "from modules.mixin_modules import (\n",
    "    RNNMixin,\n",
    "    LSTMMixin,\n",
    "    MultiScaleRetentionMixin,\n",
    "    Mamba2Mixin,\n",
    "    RWKV6Mixin,\n",
    "    GroupedQuerySelfAttentionMixin,\n",
    "    MultiHeadLatentAttentionMixin,\n",
    ")\n",
    "\n",
    "from modules.ffn_modules import FFN, SparseMoeFFN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc39648",
   "metadata": {},
   "source": [
    "## STACK 4 - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2b82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 8\n",
    "ffn_module = FFN(hidden_size, hidden_size*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4127485",
   "metadata": {},
   "source": [
    "### GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gqsa = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=True,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=GroupedQuerySelfAttentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(gqsa)\n",
    "train(gqsa,run_name='gqsa', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d42d8",
   "metadata": {},
   "source": [
    "### Retentive Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "retnet = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=True,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=MultiScaleRetentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(retnet)\n",
    "train(retnet,run_name='retnet', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6f066",
   "metadata": {},
   "source": [
    "### Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab4c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mamba = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=True,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=Mamba2Mixin(hidden_size = hidden_size, num_attention_heads=6),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mamba)\n",
    "train(mamba,run_name='mamba', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d11bb",
   "metadata": {},
   "source": [
    "### RWKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad291e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rwkv = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=True,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=RWKV6Mixin(hidden_size = hidden_size, num_attention_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(rwkv)\n",
    "train(rwkv,run_name='rwkv', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b981c5",
   "metadata": {},
   "source": [
    "## STACK 8 - Moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9471ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "ffn_module = SparseMoeFFN(\n",
    "    hidden_size,\n",
    "    hidden_size*4,\n",
    "    num_experts=8,\n",
    "    num_experts_per_tok=2,\n",
    "    norm_topk_prob=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b43ba",
   "metadata": {},
   "source": [
    "### GQA MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gqsa_moe = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=False,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=GroupedQuerySelfAttentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(gqsa_moe)\n",
    "train(gqsa_moe,run_name='gqsa-moe', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd0af3",
   "metadata": {},
   "source": [
    "### Retentive Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "retnet_moe = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=False,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=MultiScaleRetentionMixin(hidden_size, num_attention_heads=9, num_key_value_heads=3),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(retnet_moe)\n",
    "train(retnet_moe,run_name='retnet-moe', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0cc33b",
   "metadata": {},
   "source": [
    "### Mamba MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mamba_moe = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=False,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=Mamba2Mixin(hidden_size = hidden_size, num_attention_heads=6),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(mamba_moe)\n",
    "train(mamba_moe,run_name='mamba-moe', do_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ab488",
   "metadata": {},
   "source": [
    "### RWKV MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rwkv_moe = StackedMixinForCausalLM(\n",
    "    num_layers=num_layers,\n",
    "    hidden_size=hidden_size,\n",
    "    initializer_range=0.02,\n",
    "    embedding_module=embed_tokens,\n",
    "    lm_head_module=lm_head,\n",
    "    final_norm_module=norm,\n",
    "    freeze_lm_modules=False,\n",
    "    vocab_size=vocab_size,\n",
    "    mixin_module=RWKV6Mixin(hidden_size = hidden_size, num_attention_heads=9),\n",
    "    ffn_module=ffn_module,\n",
    "    # positionnal_module=NaivePositionnalEmbedding(hidden_size, max_length=max_length)\n",
    ")\n",
    "\n",
    "count_parameters(rwkv_moe)\n",
    "train(rwkv_moe,run_name='rwkv-moe', do_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3caec-54d3-46d1-94cb-e5096b687f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae90173-c7d2-4961-bd59-7632001cba02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e917bc-4467-435e-b833-40250f033cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
